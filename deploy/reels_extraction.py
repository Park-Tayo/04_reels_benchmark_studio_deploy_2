import yt_dlp
import tempfile
import os
from pathlib import Path
import subprocess
import openai
from api_config import get_api_config
import time
from functools import wraps
import requests
from datetime import datetime
import json

# ìƒëŒ€ ê²½ë¡œë¡œ ë³€ê²½ (ìŠ¤íŠ¸ë¦¼ë¦¿ í´ë¼ìš°ë“œ í˜¸í™˜)
BASE_DIR = Path(__file__).parent.parent

# ì„ì‹œ íŒŒì¼ ë””ë ‰í† ë¦¬ ì„¤ì •
TEMP_DIR = Path(tempfile.gettempdir()) / "reels_benchmark"
os.makedirs(TEMP_DIR, exist_ok=True)

def get_whisper_model():
    # ìœ„ìŠ¤í¼ ëª¨ë¸ import ì œê±°
    # import whisper ì œê±°
    return None

def timer_decorator(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        print(f"[Timer] {func.__name__}: {end_time - start_time:.2f}ì´ˆ")
        return result
    return wrapper

@timer_decorator
def extract_audio_from_url(url):
    try:
        # ì„ì‹œ íŒŒì¼ ê²½ë¡œë¥¼ í”Œë«í¼ ë…ë¦½ì ìœ¼ë¡œ ìƒì„±
        temp_audio = TEMP_DIR / f"audio_{int(time.time())}.wav"
        
        command = [
            'ffmpeg',
            '-i', url,
            '-vn',
            '-acodec', 'pcm_s16le',
            '-ar', '16000',
            '-ac', '1',
            '-y',
            str(temp_audio)  # Path ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        ]
        
        subprocess.run(command, check=True, capture_output=True)
        return str(temp_audio)
    except Exception as e:
        print(f"ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None

@timer_decorator
def transcribe_video(video_url):
    try:
        audio_path = extract_audio_from_url(video_url)
        if not audio_path:
            return ""
            
        # OpenAI APIë¥¼ ì‚¬ìš©í•œ ìŒì„± ì¸ì‹
        api_config = get_api_config()
        client = openai.OpenAI(api_key=api_config["api_key"])
        
        with open(audio_path, 'rb') as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="ko"  # í•œêµ­ì–´ ì„¤ì •
            )
        
        os.remove(audio_path)
        return transcript.text
        
    except Exception as e:
        print(f"ì „ì‚¬ ì˜¤ë¥˜: {e}")
        return ""

@timer_decorator
def extract_reels_info(url, video_analysis):
    """
    ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜ìœ¼ë¡œ ë¦´ìŠ¤ ì •ë³´ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
    """
    try:
        reels_info = {
            'caption': video_analysis.get('caption', ''),
            'refined_transcript': video_analysis.get('transcript', '')
        }
        
        return reels_info
            
    except Exception as e:
        print(f"\nì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return f"Error: {str(e)}"

@timer_decorator
def process_transcript_and_caption(transcript, caption, video_analysis):
    """ìŠ¤í¬ë¦½íŠ¸ì™€ ìº¡ì…˜ì˜ ë²ˆì—­/ì •ì œë¥¼ í•˜ë‚˜ì˜ GPT í˜¸ì¶œë¡œ í†µí•©"""
    try:
        api_config = get_api_config()
        client = openai.OpenAI(api_key=api_config["api_key"])
        
        prompt = f"""
        ë‹¤ìŒì€ ì˜ìƒì˜ ìŠ¤í¬ë¦½íŠ¸ì™€ ìº¡ì…˜ì…ë‹ˆë‹¤. ê°ê°ì— ëŒ€í•´ ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
        1. ì˜ì–´ë¡œ ëœ ê²½ìš° í•œêµ­ì–´ë¡œ ë²ˆì—­ (ë‹¨, ì „ë¬¸ìš©ì–´/ë¸Œëœë“œëª…/í•´ì‹œíƒœê·¸ëŠ” ì›ë¬¸ ìœ ì§€)
        2. ì´ëª¨í‹°ì½˜ê³¼ íŠ¹ìˆ˜ë¬¸ìëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
        3. ì „ì²´ì ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì •ì œ
        
        ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸:
        {transcript}
        
        ì›ë³¸ ìº¡ì…˜:
        {caption}
        
        ì˜ìƒ ë¶„ì„ ë‚´ìš©:
        - ì´ˆë°˜ 3ì´ˆ (ì¹´í”¼ë¼ì´íŒ…): {video_analysis.get('intro_copy', '')}
        - ì´ˆë°˜ 3ì´ˆ (ì˜ìƒ êµ¬ì„±): {video_analysis.get('intro_structure', '')}
        - ë‚˜ë ˆì´ì…˜: {video_analysis.get('narration', '')}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì£¼ì„¸ìš”:
        ---ìŠ¤í¬ë¦½íŠ¸---
        [ì •ì œëœ ìŠ¤í¬ë¦½íŠ¸]
        ---ìº¡ì…˜---
        [ì •ì œëœ ìº¡ì…˜]
        """
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ ë²ˆì—­ê°€ì´ì ìŠ¤í¬ë¦½íŠ¸ êµì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=1000
        )
        
        result = response.choices[0].message.content.strip()
        
        # ê²°ê³¼ íŒŒì‹±
        transcript_part = result.split("---ìº¡ì…˜---")[0].replace("---ìŠ¤í¬ë¦½íŠ¸---", "").strip()
        caption_part = result.split("---ìº¡ì…˜---")[1].strip()
        
        return {
            "transcript": transcript_part,
            "caption": caption_part
        }
        
    except Exception as e:
        print(f"í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {
            "transcript": transcript,
            "caption": caption
        }

@timer_decorator
def download_video(url):
    try:
        ydl_opts = {
            'format': 'best',
            'outtmpl': str(TEMP_DIR / '%(id)s.%(ext)s'),  # ì„ì‹œ ë””ë ‰í† ë¦¬ì— ì €ì¥
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=False)
            video_url = info['url']
            
            # ì„ì‹œ íŒŒì¼ ìƒì„±
            temp_video = TEMP_DIR / f"video_{int(time.time())}.mp4"
            
            # ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
            print("ğŸ“¥ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            response = requests.get(video_url, stream=True)
            total_size = int(response.headers.get('content-length', 0))
            
            with open(temp_video, 'wb') as video_file:
                if total_size == 0:
                    video_file.write(response.content)
                else:
                    downloaded = 0
                    for data in response.iter_content(chunk_size=4096):
                        downloaded += len(data)
                        video_file.write(data)
                        
            print("âœ… ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
            return str(temp_video)
            
    except Exception as e:
        print(f"âš ï¸ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return None

def analyze_with_gpt4(info, input_data):
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë¦´ìŠ¤ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    try:
        api_config = get_api_config()
        client = openai.OpenAI(api_key=api_config["api_key"])
        
        messages = [
            {
                "role": "system",
                "content": """ë‹¹ì‹ ì€ ë¦´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤..."""  # ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ìœ ì§€
            },
            {
                "role": "user",
                "content": f"""
                ë‹¤ìŒ ë¦´ìŠ¤ë¥¼ ë¶„ì„í•˜ê³ , ì…ë ¥ëœ ì£¼ì œì— ë§ê²Œ ë²¤ì¹˜ë§ˆí‚¹ ê¸°íšì„ í•´ì£¼ì„¸ìš”:
                
                ìŠ¤í¬ë¦½íŠ¸: {info['refined_transcript']}
                ìº¡ì…˜: {info['caption']}
                
                ì‚¬ìš©ì ì…ë ¥ ì •ë³´:
                - ì´ˆë°˜ 3ì´ˆ ì¹´í”¼ë¼ì´íŒ…: {input_data['video_analysis']['intro_copy']}
                - ì´ˆë°˜ 3ì´ˆ ì˜ìƒ êµ¬ì„±: {input_data['video_analysis']['intro_structure']}
                - ë‚˜ë ˆì´ì…˜: {input_data['video_analysis']['narration']}
                - ìŒì•…: {input_data['video_analysis']['music']}
                - í°íŠ¸: {input_data['video_analysis']['font']}
                
                ë²¤ì¹˜ë§ˆí‚¹í•  ìƒˆë¡œìš´ ì£¼ì œ: {input_data['content_info']['topic']}
                """
            }
        ]
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0,
            max_tokens=2000
        )
        
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        return f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"